@inproceedings{Son2019,
author = {Son, Jeongmin and Ahn, Sunggeun and Kim, Sunbum and Lee, Geehyuk},
title = {Improving Two-Thumb Touchpad Typing in Virtual Reality},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3312926},
doi = {10.1145/3290607.3312926},
abstract = {Two-Thumb Touchpad Typing (4T) using hand-held controllers is one of the common text entry techniques in Virtual Reality (VR). However, its performance is far below that of two-thumb typing on a smartphone. We explored the possibility of improving its performance focusing on the following two factors: the visual feedback of hovering thumbs and the grip stability of the controllers. We examined the effects of these two factors on the performance of 4T in VR in user experiments. Their results show that hover feedback had a significant main effect on the 4T performance, but grip stability did not. We then investigated the achievable performance of the final 4T design in a longitudinal study, and its results show that users could achieve a typing speed over 30 words per minute after two hours of practice.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {virtual reality, two-thumb touchpad typing, text entry},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{Knierim2018,
author = {Knierim, Pascal and Schwind, Valentin and Feit, Anna Maria and Nieuwenhuizen, Florian and Henze, Niels},
title = {Physical Keyboards in Virtual Reality: Analysis of Typing Performance and Effects of Avatar Hands},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173919},
doi = {10.1145/3173574.3173919},
abstract = {Entering text is one of the most common tasks when interacting with computing systems. Virtual Reality (VR) presents a challenge as neither the user's hands nor the physical input devices are directly visible. Hence, conventional desktop peripherals are very slow, imprecise, and cumbersome. We developed a apparatus that tracks the user's hands, and a physical keyboard, and visualize them in VR. In a text input study with 32 participants, we investigated the achievable text entry speed and the effect of hand representations and transparency on typing performance, workload, and presence. With our apparatus, experienced typists benefited from seeing their hands, and reach almost outside-VR performance. Inexperienced typists profited from semi-transparent hands, which enabled them to type just 5.6 WPM slower than with a regular desktop setup. We conclude that optimizing the visualization of hands in VR is important, especially for inexperienced typists, to enable a high typing performance.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–9},
numpages = {9},
keywords = {hands, physical keyboard, text entry, virtual reality},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@article{Boletsis2019,
  author = {Boletsis, Costas and Chorianopoulos, Konstantinos},
  title = {Controller-based Text-input Techniques for Virtual Reality: An Empirical Comparison},
  journal = {International Journal of Virtual Reality},
  volume = {19},
  number = {3},
  year = {2019},
  pages = {1--12},
  url = {http://ijvr.eu/article/view/2917},
  note = {Accessed: 2023-10-15}
}

@inproceedings{Walker2017,
  author = {Walker, Jerald Thomas and Li, Bo and Vertanen, Keith and Kuhl, Scott A.},
  title = {Efficient Typing on a Visually Occluded Physical Keyboard},
  booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
  year = {2017},
  pages = {5457--5461},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/3025453.3025783},
  url = {https://digitalcommons.mtu.edu/michigantech-p/1106/}
}

@inproceedings{Grubert2018,
  author = {Grubert, Jens and Witzani, Lukas and Ofek, Eyal and Pahud, Michel and Kranz, Matthias and Kristensson, Per Ola},
  title = {Text Entry in Immersive Head-Mounted Display-Based Virtual Reality Using Standard Keyboards},
  booktitle = {2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  year = {2018},
  pages = {159--166},
  publisher = {IEEE},
  address = {Reutlingen, Germany},
  doi = {10.1109/VR.2018.8447569}
}

@INPROCEEDINGS{Giovannelli2022,
  author={Giovannelli, Alexander and Lisle, Lee and Bowman, Doug A.},
  booktitle={2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={Exploring the Impact of Visual Information on Intermittent Typing in Virtual Reality}, 
  year={2022},
  volume={},
  number={},
  pages={8-17},
  keywords={Performance evaluation;Visualization;Keyboards;Virtual environments;User experience;Task analysis;Augmented reality;Human-centered computing;Human computer interaction (HCI);Interaction devices;Keyboards Human-centered computing;Interaction paradigms;Virtual reality},
  doi={10.1109/ISMAR55827.2022.00014}
}

@INPROCEEDINGS{Dudley2019,
  author={Dudley, John and Benko, Hrvoje and Wigdor, Daniel and Kristensson, Per Ola},
  booktitle={2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={Performance Envelopes of Virtual Keyboard Text Input Strategies in Virtual Reality}, 
  year={2019},
  volume={},
  number={},
  pages={289-300},
  keywords={Keyboards;Tracking;Layout;Decoding;Augmented reality;Performance evaluation;Indexes;virtual reality;text entry;head mounted display},
  doi={10.1109/ISMAR.2019.00027}
}

@inproceedings{Foy2021,
author = {Foy, Conor R. and Dudley, John J. and Gupta, Aakar and Benko, Hrvoje and Kristensson, Per Ola},
title = {Understanding, Detecting and Mitigating the Effects of Coactivations in Ten-Finger Mid-Air Typing in Virtual Reality},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445671},
doi = {10.1145/3411764.3445671},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {287},
numpages = {11},
keywords = {virtual reality, text entry},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{Zaman2022,
  title={Effects of virtual hands on physical demands and task performance for typing in virtual reality},
  author={Zaman, Mobasshira and Alluri, Chandra Shekhar Verma and Hwang, Jaejin},
  booktitle={Proceedings of the XXXIVth Annual International Occupational Ergonomics and Safety Conference. Presented at the XXXIVth Annual International Occupational Ergonomics and Safety Conference, International Society for Occupational Ergonomics and Safety},
  pages={47--53},
  year={2022}
}

@INPROCEEDINGS{Lougiakis2020,
  author={Lougiakis, Christos and Katifori, Akrivi and Roussou, Maria and Ioannidis, Ioannis-Panagiotis},
  booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
  title={Effects of Virtual Hand Representation on Interaction and Embodiment in HMD-based Virtual Environments Using Controllers}, 
  year={2020},
  volume={},
  number={},
  pages={510-518},
  keywords={Virtual environments;Virtual reality;Human computer interaction;Grasping;Human-centered computing;Virtual reality;Human-centered computing;User studies;Human-centered computing;Empirical studies in interaction design;Computing methodologies;Perception},
  doi={10.1109/VR46266.2020.00072}}

@ARTICLE{Venkatakrishnan2023,
  author={Venkatakrishnan, Roshan and Venkatakrishnan, Rohith and Raveendranath, Balagopal and Pagano, Christopher C. and Robb, Andrew C. and Lin, Wen-Chieh and Babu, Sabarish V.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={How Virtual Hand Representations Affect the Perceptions of Dynamic Affordances in Virtual Reality}, 
  year={2023},
  volume={29},
  number={5},
  pages={2258-2268},
  keywords={Task analysis;End effectors;Affordances;Tracking;Visualization;Grasping;Cameras;Affordance;Passability;Self-Avatar;Virtual Reality},
  doi={10.1109/TVCG.2023.3247041}}

@INPROCEEDINGS{Zhang2020,
  author={Zhang, Jingjing and Huang, Mengjie and Zhao, Lixiang and Yang, Rui and Liang, Hai-Ning and Han, Ji and Wang, Liu and Sun, Wenxin},
  booktitle={2020 13th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={Influence of Hand Representation Design on Presence and Embodiment in Virtual Environment}, 
  year={2020},
  volume={},
  number={},
  pages={364-367},
  keywords={Task analysis;Correlation;Virtual environments;Avatars;Standards;Shape;Wrist;virtual reality;hand representation;presence;embodiment;body ownership;agency},
  doi={10.1109/ISCID51228.2020.00088}}

@inproceedings{Kim2013,
  author    = {Kim, J. H. and Aulck, L. and Thamsuwan, O. and Bartha, M. C. and Johnson, P. W.},
  title     = {The Effects of Virtual Keyboard Key Sizes on Typing Productivity and Physical Exposures},
  booktitle = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  year      = {2013},
  volume    = {57},
  number    = {1},
  pages     = {887--891},
  doi       = {10.1177/1541931213571193},
  url       = {https://doi.org/10.1177/1541931213571193},
  note      = {Original work published 2013}
}

@ARTICLE{Chellali2025,
  author={Chellali, Amine and Herfort, Lucas and Loup, Guillaume and Ferrer, Marie-Hélène},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={The Impact of Visual and Haptic Feedback on Keyboard Typing in Immersive Virtual Environments}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  keywords={Keyboards;Haptic interfaces;Visualization;Hands;Virtual environments;Fingers;Electronic mail;Training;Accuracy;Tracking;Input techniques;Virtual keyboard;Text entry;Immersive environments},
  doi={10.1109/TVCG.2025.3549555}}


@article{Kalava2014,
    author = {Kalava, Arun and Ravindranath, Sapna and Bronshteyn, Inessa and Munjal, Ripudaman S. and SchianodiCola, Joseph and Yarmush, Joel M.},
    title = {Typing Skills of Physicians in Training},
    journal = {Journal of Graduate Medical Education},
    volume = {6},
    number = {1},
    pages = {155-157},
    year = {2014},
    month = {03},
    abstract = {There is an increasing use of electronic health records in hospitals across the United States. The speed and accuracy of residents in documenting electronic health records has been insufficiently addressed.We studied resident typing skills at New York Methodist Hospital. Participating residents typed a standard 100-word alphanumerical paragraph of a patient's medical history. Typing skills were assessed by calculating the net words per minute (WPM). Typing skills were categorized as follows: (1) fewer than 26 net WPM as very slow; (2) 26 to 35 net WPM as slow; (3) 35 to 45 net WPM as intermediate; and (4) greater than 45 net WPM as fast. Residents were further categorized into (1) American medical graduates; (2) American international medical graduates; and (3) non-American international medical graduates.A total of 104 of 280 residents (37\%) participated in the study. There was equal representation from various specialties, backgrounds, and all postgraduate levels of training. The median typing speed was 30.4 net WPM. Typing skills were very slow (34 of 104, 33\%), slow (28 of 104, 27\%), intermediate (29 of 104, 28\%), and fast (13 of 104, 12\%) among the residents. Typing skills of non-American international medical graduates (mean net WPM of 25.9) were significantly slower than those of American medical graduates (mean net WPM of 35.9) and American international medical graduates (mean net WPM of 33.5).Most residents (60\%, 62 of 104) who participated in the study at our institute lacked typing skills. As the use of electronic health records increases, a lack of typing skills may impact residents' time for learning and patient care.},
    issn = {1949-8349},
    doi = {10.4300/JGME-D-13-00164.1},
    url = {https://doi.org/10.4300/JGME-D-13-00164.1},
    eprint = {https://meridian.allenpress.com/jgme/article-pdf/6/1/155/2221089/jgme-d-13-00164\_1.pdf},
}

@inproceedings{Speicher2018,
author = {Speicher, Marco and Feit, Anna Maria and Ziegler, Pascal and Kr\"{u}ger, Antonio},
title = {Selection-based Text Entry in Virtual Reality},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174221},
doi = {10.1145/3173574.3174221},
abstract = {In recent years, Virtual Reality (VR) and 3D User Interfaces (3DUI) have seen a drastic increase in popularity, especially in terms of consumer-ready hardware and software. While the technology for input as well as output devices is market ready, only a few solutions for text input exist, and empirical knowledge about performance and user preferences is lacking. In this paper, we study text entry in VR by selecting characters on a virtual keyboard. We discuss the design space for assessing selection-based text entry in VR. Then, we implement six methods that span different parts of the design space and evaluate their performance and user preferences. Our results show that pointing using tracked hand-held controllers outperforms all other methods. Other methods such as head pointing can be viable alternatives depending on available resources. We summarize our findings by formulating guidelines for choosing optimal virtual keyboard text entry methods in VR.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {virtual reality, user experience, text entry, task performance, pointing, mid-air},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@misc{Kumar2024, 
title={Virtual reality statistics 2025: Users Data (updated)},
url={https://www.demandsage.com/virtual-reality-statistics/}, 
journal={DemandSage}, 
publisher={DemandSage}, 
author={Kumar, Naveen}, 
year={2024}, 
month={Dec}
} 

@inproceedings{Zhao2023,
author = {Zhao, Maozheng and Pierce, Alec M and Tan, Ran and Zhang, Ting and Wang, Tianyi and Jonker, Tanya R. and Benko, Hrvoje and Gupta, Aakar},
title = {Gaze Speedup: Eye Gaze Assisted Gesture Typing in Virtual Reality},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584072},
doi = {10.1145/3581641.3584072},
abstract = {Mid-air text input in augmented or virtual reality (AR/VR) is an open problem. One proposed solution is gesture typing where the user performs a gesture trace over the keyboard. However, this requires the user to move their hands precisely and continuously, potentially causing arm fatigue. With eye tracking available on AR/VR devices, multiple works have proposed gaze-driven gesture typing techniques. However, such techniques require the explicit use of gaze which are prone to Midas touch problems, conflicting with other gaze activities in the same moment. In this work, the user is not made aware that their gaze is being used to improve the interaction, making the use of gaze completely implicit. We observed that a user’s implicit gaze fixation location during gesture typing is usually the gesture cursor’s target location if the gesture cursor is moving toward it. Based on this observation, we propose the Speedup method in which we speed up the gesture cursor toward the user’s gaze fixation location, the speedup rate depends on how well the gesture cursor’s moving direction aligns with the gaze fixation. To reduce the overshooting near the target in the Speedup method, we further proposed the Gaussian Speedup method in which the speedup rate is dynamically reduced with a Gaussian function when the gesture cursor gets nearer to the gaze fixation. Using a wrist IMU as input, a 12-person study demonstrated that the Speedup method and Gaussian Speedup method reduced users’ hand movement by and respectively without any loss of typing speed or accuracy.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {595–606},
numpages = {12},
keywords = {gesture input, implicit eye gaze, virtual reality},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

@INPROCEEDINGS{Hu2024,
  author={Hu, Jinghui and Dudley, John J. and Kristensson, Per Ola},
  booktitle={2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}, 
  title={SkiMR: Dwell-free Eye Typing in Mixed Reality}, 
  year={2024},
  volume={},
  number={},
  pages={439-449},
  keywords={Headphones;Three-dimensional displays;Error analysis;Mixed reality;Keyboards;Virtual reality;User interfaces;Text input;Mixed / augmented reality;Keyboards},
  doi={10.1109/VR58804.2024.00065}
}

@inproceedings{Rajanna2018,
author = {Rajanna, Vijay and Hansen, John Paulin},
title = {Gaze typing in virtual reality: impact of keyboard design, selection method, and motion},
year = {2018},
isbn = {9781450357067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3204493.3204541},
doi = {10.1145/3204493.3204541},
abstract = {Gaze tracking in virtual reality (VR) allows for hands-free text entry, but it has not yet been explored. We investigate how the keyboard design, selection method, and motion in the field of view may impact typing performance and user experience. We present two studies of people (n = 32) typing with gaze+dwell and gaze+click inputs in VR. In study 1, the typing keyboard was flat and within-view; in study 2, it was larger-than-view but curved. Both studies included a stationary and a dynamic motion conditions in the user's field of view.Our findings suggest that 1) gaze typing in VR is viable but constrained, 2) the users perform best (10.15 WPM) when the entire keyboard is within-view; the larger-than-view keyboard (9.15 WPM) induces physical strain due to increased head movements, 3) motion in the field of view impacts the user's performance: users perform better while stationary than when in motion, and 4) gaze+click is better than dwell only (fixed at 550 ms) interaction.},
booktitle = {Proceedings of the 2018 ACM Symposium on Eye Tracking Research \& Applications},
articleno = {15},
numpages = {10},
keywords = {virtual reality, multi-modal input, motion, mental and physical workload, keyboard design, gaze typing, dwell, VR sickness},
location = {Warsaw, Poland},
series = {ETRA '18}
}